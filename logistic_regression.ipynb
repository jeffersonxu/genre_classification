{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3350b16d-edad-4b63-b5f2-ddbbd6c85e9e",
   "metadata": {},
   "source": [
    "# Logistic Regression Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192ed3d4-47a7-4ab3-906b-0ffa89d49f2c",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e748f7f-8831-4d3e-9347-ec7c0bc50724",
   "metadata": {},
   "source": [
    "### Load cleaned data as df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f3f00bc-b704-4b45-8f32-48b4ff5518d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83390e9-47a9-4ffd-86dd-03a32c943da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>music_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.01270</td>\n",
       "      <td>0.622</td>\n",
       "      <td>218293.0</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>D</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-7.043</td>\n",
       "      <td>Minor</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>115.002</td>\n",
       "      <td>0.531</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.00306</td>\n",
       "      <td>0.620</td>\n",
       "      <td>215613.0</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>G#</td>\n",
       "      <td>0.534</td>\n",
       "      <td>-4.617</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>127.994</td>\n",
       "      <td>0.333</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.02540</td>\n",
       "      <td>0.774</td>\n",
       "      <td>166875.0</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>C#</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-4.498</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>128.014</td>\n",
       "      <td>0.270</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.638</td>\n",
       "      <td>222369.0</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.909000</td>\n",
       "      <td>F#</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-6.266</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0413</td>\n",
       "      <td>145.036</td>\n",
       "      <td>0.323</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.02890</td>\n",
       "      <td>0.572</td>\n",
       "      <td>214408.0</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>B</td>\n",
       "      <td>0.106</td>\n",
       "      <td>-4.294</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.3510</td>\n",
       "      <td>149.995</td>\n",
       "      <td>0.230</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40555</th>\n",
       "      <td>49999</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.13300</td>\n",
       "      <td>0.849</td>\n",
       "      <td>237667.0</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>C</td>\n",
       "      <td>0.296</td>\n",
       "      <td>-7.195</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0516</td>\n",
       "      <td>99.988</td>\n",
       "      <td>0.629</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40556</th>\n",
       "      <td>50001</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.15700</td>\n",
       "      <td>0.709</td>\n",
       "      <td>251860.0</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>B</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-9.814</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>122.043</td>\n",
       "      <td>0.113</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40557</th>\n",
       "      <td>50002</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.00597</td>\n",
       "      <td>0.693</td>\n",
       "      <td>189483.0</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>D</td>\n",
       "      <td>0.143</td>\n",
       "      <td>-5.443</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>131.079</td>\n",
       "      <td>0.395</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40558</th>\n",
       "      <td>50003</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.08310</td>\n",
       "      <td>0.782</td>\n",
       "      <td>262773.0</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>G</td>\n",
       "      <td>0.106</td>\n",
       "      <td>-5.016</td>\n",
       "      <td>Minor</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>75.886</td>\n",
       "      <td>0.354</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40559</th>\n",
       "      <td>50004</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.10200</td>\n",
       "      <td>0.862</td>\n",
       "      <td>267267.0</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>F#</td>\n",
       "      <td>0.272</td>\n",
       "      <td>-13.652</td>\n",
       "      <td>Minor</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>99.201</td>\n",
       "      <td>0.765</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40560 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Column  popularity  acousticness  danceability  duration_ms  energy  \\\n",
       "0           1        31.0       0.01270         0.622     218293.0   0.890   \n",
       "1           2        28.0       0.00306         0.620     215613.0   0.755   \n",
       "2           3        34.0       0.02540         0.774     166875.0   0.700   \n",
       "3           4        32.0       0.00465         0.638     222369.0   0.587   \n",
       "4           6        46.0       0.02890         0.572     214408.0   0.803   \n",
       "...       ...         ...           ...           ...          ...     ...   \n",
       "40555   49999        56.0       0.13300         0.849     237667.0   0.660   \n",
       "40556   50001        72.0       0.15700         0.709     251860.0   0.362   \n",
       "40557   50002        51.0       0.00597         0.693     189483.0   0.763   \n",
       "40558   50003        65.0       0.08310         0.782     262773.0   0.472   \n",
       "40559   50004        67.0       0.10200         0.862     267267.0   0.642   \n",
       "\n",
       "       instrumentalness key  liveness  loudness   mode  speechiness    tempo  \\\n",
       "0              0.950000   D     0.124    -7.043  Minor       0.0300  115.002   \n",
       "1              0.011800  G#     0.534    -4.617  Major       0.0345  127.994   \n",
       "2              0.002530  C#     0.157    -4.498  Major       0.2390  128.014   \n",
       "3              0.909000  F#     0.157    -6.266  Major       0.0413  145.036   \n",
       "4              0.000008   B     0.106    -4.294  Major       0.3510  149.995   \n",
       "...                 ...  ..       ...       ...    ...          ...      ...   \n",
       "40555          0.000008   C     0.296    -7.195  Major       0.0516   99.988   \n",
       "40556          0.000000   B     0.109    -9.814  Major       0.0550  122.043   \n",
       "40557          0.000000   D     0.143    -5.443  Major       0.1460  131.079   \n",
       "40558          0.000000   G     0.106    -5.016  Minor       0.0441   75.886   \n",
       "40559          0.000000  F#     0.272   -13.652  Minor       0.1010   99.201   \n",
       "\n",
       "       valence music_genre  \n",
       "0        0.531  Electronic  \n",
       "1        0.333  Electronic  \n",
       "2        0.270  Electronic  \n",
       "3        0.323  Electronic  \n",
       "4        0.230  Electronic  \n",
       "...        ...         ...  \n",
       "40555    0.629     Hip-Hop  \n",
       "40556    0.113     Hip-Hop  \n",
       "40557    0.395     Hip-Hop  \n",
       "40558    0.354     Hip-Hop  \n",
       "40559    0.765     Hip-Hop  \n",
       "\n",
       "[40560 rows x 15 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('music-genre-cleaned-2.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8f8f8e-efb3-4ca6-81ef-a42ebab5c008",
   "metadata": {},
   "source": [
    "### Encode labels \"key\" and \"mode\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afb3eaa7-9193-4517-8be3-36bb5997110c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>music_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.01270</td>\n",
       "      <td>0.622</td>\n",
       "      <td>218293.0</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-7.043</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>115.002</td>\n",
       "      <td>0.531</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.00306</td>\n",
       "      <td>0.620</td>\n",
       "      <td>215613.0</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>11</td>\n",
       "      <td>0.534</td>\n",
       "      <td>-4.617</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>127.994</td>\n",
       "      <td>0.333</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.02540</td>\n",
       "      <td>0.774</td>\n",
       "      <td>166875.0</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>4</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-4.498</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>128.014</td>\n",
       "      <td>0.270</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.638</td>\n",
       "      <td>222369.0</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.909000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-6.266</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0413</td>\n",
       "      <td>145.036</td>\n",
       "      <td>0.323</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.02890</td>\n",
       "      <td>0.572</td>\n",
       "      <td>214408.0</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>2</td>\n",
       "      <td>0.106</td>\n",
       "      <td>-4.294</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3510</td>\n",
       "      <td>149.995</td>\n",
       "      <td>0.230</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column  popularity  acousticness  danceability  duration_ms  energy  \\\n",
       "0       1        31.0       0.01270         0.622     218293.0   0.890   \n",
       "1       2        28.0       0.00306         0.620     215613.0   0.755   \n",
       "2       3        34.0       0.02540         0.774     166875.0   0.700   \n",
       "3       4        32.0       0.00465         0.638     222369.0   0.587   \n",
       "4       6        46.0       0.02890         0.572     214408.0   0.803   \n",
       "\n",
       "   instrumentalness  key  liveness  loudness  mode  speechiness    tempo  \\\n",
       "0          0.950000    5     0.124    -7.043     1       0.0300  115.002   \n",
       "1          0.011800   11     0.534    -4.617     0       0.0345  127.994   \n",
       "2          0.002530    4     0.157    -4.498     0       0.2390  128.014   \n",
       "3          0.909000    9     0.157    -6.266     0       0.0413  145.036   \n",
       "4          0.000008    2     0.106    -4.294     0       0.3510  149.995   \n",
       "\n",
       "   valence music_genre  \n",
       "0    0.531  Electronic  \n",
       "1    0.333  Electronic  \n",
       "2    0.270  Electronic  \n",
       "3    0.323  Electronic  \n",
       "4    0.230  Electronic  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode categorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "data[\"key\"] = LabelEncoder().fit_transform(data[\"key\"])\n",
    "data[\"mode\"] = LabelEncoder().fit_transform(data[\"mode\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf0e6d6-738b-45cd-8508-8225013ffb6d",
   "metadata": {},
   "source": [
    "### Split data into features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89343489-2c34-4281-8198-96c685b5bd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       popularity  acousticness  danceability  duration_ms  energy  \\\n",
      "0            31.0       0.01270         0.622     218293.0   0.890   \n",
      "1            28.0       0.00306         0.620     215613.0   0.755   \n",
      "2            34.0       0.02540         0.774     166875.0   0.700   \n",
      "3            32.0       0.00465         0.638     222369.0   0.587   \n",
      "4            46.0       0.02890         0.572     214408.0   0.803   \n",
      "...           ...           ...           ...          ...     ...   \n",
      "40555        56.0       0.13300         0.849     237667.0   0.660   \n",
      "40556        72.0       0.15700         0.709     251860.0   0.362   \n",
      "40557        51.0       0.00597         0.693     189483.0   0.763   \n",
      "40558        65.0       0.08310         0.782     262773.0   0.472   \n",
      "40559        67.0       0.10200         0.862     267267.0   0.642   \n",
      "\n",
      "       instrumentalness  key  liveness  loudness  mode  speechiness    tempo  \\\n",
      "0              0.950000    5     0.124    -7.043     1       0.0300  115.002   \n",
      "1              0.011800   11     0.534    -4.617     0       0.0345  127.994   \n",
      "2              0.002530    4     0.157    -4.498     0       0.2390  128.014   \n",
      "3              0.909000    9     0.157    -6.266     0       0.0413  145.036   \n",
      "4              0.000008    2     0.106    -4.294     0       0.3510  149.995   \n",
      "...                 ...  ...       ...       ...   ...          ...      ...   \n",
      "40555          0.000008    3     0.296    -7.195     0       0.0516   99.988   \n",
      "40556          0.000000    2     0.109    -9.814     0       0.0550  122.043   \n",
      "40557          0.000000    5     0.143    -5.443     0       0.1460  131.079   \n",
      "40558          0.000000   10     0.106    -5.016     1       0.0441   75.886   \n",
      "40559          0.000000    9     0.272   -13.652     1       0.1010   99.201   \n",
      "\n",
      "       valence  \n",
      "0        0.531  \n",
      "1        0.333  \n",
      "2        0.270  \n",
      "3        0.323  \n",
      "4        0.230  \n",
      "...        ...  \n",
      "40555    0.629  \n",
      "40556    0.113  \n",
      "40557    0.395  \n",
      "40558    0.354  \n",
      "40559    0.765  \n",
      "\n",
      "[40560 rows x 13 columns]\n",
      "0        Electronic\n",
      "1        Electronic\n",
      "2        Electronic\n",
      "3        Electronic\n",
      "4        Electronic\n",
      "            ...    \n",
      "40555       Hip-Hop\n",
      "40556       Hip-Hop\n",
      "40557       Hip-Hop\n",
      "40558       Hip-Hop\n",
      "40559       Hip-Hop\n",
      "Name: music_genre, Length: 40560, dtype: object\n"
     ]
    }
   ],
   "source": [
    "features = data.drop(\"music_genre\", axis=1).drop(\"Column\", axis=1)\n",
    "targets = data['music_genre']\n",
    "print(features)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007c58f9-a937-44c9-a334-19e7fdb428e2",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c64bc2-7ab0-4ce1-a90c-8ae5a769eda9",
   "metadata": {},
   "source": [
    "### Minmax scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "470462f0-c554-4b42-8c98-af8ab28a7656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a2aaa9-8fff-4921-bca1-6362b75365f3",
   "metadata": {},
   "source": [
    "### Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03212431-cd68-40a0-86ae-1486a1a12b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features,targets,test_size=0.1,stratify=targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb81ea10-21e1-4c74-bff1-6e32f4518090",
   "metadata": {},
   "source": [
    "### Find optimal meta parameters using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aea4ee14-d2a3-4b51-b251-2f3057900e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "100 fits failed out of a total of 200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1519, in fit\n",
      "    multi_class = _check_multi_class(self.multi_class, solver, len(self.classes_))\n",
      "  File \"c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 483, in _check_multi_class\n",
      "    raise ValueError(\"Solver %s does not support a multinomial backend.\" % solver)\n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\users\\nickt\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.50520501        nan 0.50525979 0.50342437\n",
      " 0.50347916 0.50290387 0.50353394 0.50342437        nan        nan\n",
      "        nan        nan        nan 0.50506805 0.50495848        nan\n",
      " 0.50506804 0.50501326        nan        nan        nan        nan\n",
      " 0.52703827 0.52523021 0.52413447        nan 0.52512063 0.52523021\n",
      "        nan        nan        nan        nan        nan 0.52775049\n",
      " 0.52495632        nan 0.5277231  0.52755874]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'multi_class': 'multinomial', 'penalty': 'none', 'solver': 'newton-cg'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "estimator = LogisticRegression()\n",
    "param_grid = {  \n",
    "    'penalty': ['l1','l2','elasticnet','none'],\n",
    "    'solver': ['newton-cg','lbfgs','liblinear','sag','saga'],\n",
    "    'multi_class': ['ovr','multinomial']\n",
    "             }\n",
    "grid_search = GridSearchCV(estimator,param_grid=param_grid,cv=5)\n",
    "grid_search.fit(X_train,y_train)\n",
    "grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637712ea-cb17-423f-b6ea-002264d76eb4",
   "metadata": {},
   "source": [
    "## F1 Score and ROC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9723fb9-0665-4a58-a0cd-bf30d4a86065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.5255664683457386\n",
      "ROC score: 0.9052056752872784\n",
      "F1 score: 0.5295459029450672\n",
      "ROC score: 0.9071352392588494\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "model = LogisticRegression(multi_class='multinomial', penalty='none',solver='newton-cg')\n",
    "fit = model.fit(X_train, y_train)\n",
    "\n",
    "train_predictions = model.predict(X_train)\n",
    "print(f\"F1 score: {f1_score(y_train, train_predictions, average = 'weighted')}\")\n",
    "print(f\"ROC score: {roc_auc_score(y_train, fit.predict_proba(X_train), multi_class='ovr')}\")\n",
    "\n",
    "test_predictions = model.predict(X_test)\n",
    "print(f\"F1 score: {f1_score(y_test, test_predictions, average = 'weighted')}\")\n",
    "print(f\"ROC score: {roc_auc_score(y_test, fit.predict_proba(X_test), multi_class='ovr')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faea2c5-a35e-4422-b460-6779671e70d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
